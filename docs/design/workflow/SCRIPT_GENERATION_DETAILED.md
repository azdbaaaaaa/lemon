# 剧本生成详细流程说明

## 概述

剧本生成阶段包含两个核心步骤，用于将原始输入（小说、文档、图片等）转换为可用于视频制作的解说文案（narration）。这两个步骤确保了生成文案的质量和规范性。

## 步骤1: 生成解说文案（带检查）

### 命令
```bash
python gen_script_v2.py data/001
```

### 功能描述
根据输入文本生成解说文案，并在生成过程中进行质量检查。

### 详细处理流程

#### 1.1 输入准备
- **输入路径**: `data/001` (工作流数据目录)
- **输入文件类型**: 
  - TXT文本文件
  - Word文档 (.doc, .docx)
  - PDF文档
  - 图片文件（OCR识别）

#### 1.2 文档解析阶段
1. **文件识别**: 根据文件扩展名识别文件类型
2. **内容提取**:
   - TXT: 直接读取文本内容
   - Word: 使用文档解析库提取文本和格式
   - PDF: 使用PDF解析库提取文本内容
   - 图片: 使用OCR技术识别文本内容
3. **编码处理**: 统一转换为UTF-8编码
4. **文本清理**: 去除特殊字符、多余空白等

#### 1.3 章节分割阶段
1. **章节识别**: 
   - 识别章节标题（如"第一章"、"Chapter 1"等）
   - 识别章节分隔符
2. **章节分割**: 将文档按章节分割成多个独立单元
3. **章节元数据**: 记录每个章节的标题、起始位置、长度等信息

#### 1.4 AI生成阶段
1. **Prompt构建**: 
   - 为每个章节构建生成Prompt
   - 包含章节内容、生成要求、格式规范等
2. **AI服务调用**:
   - 支持的AI服务: Gemini3 Pro、豆包等
   - 调用AI服务的文本生成接口
   - 传递章节内容和生成参数
3. **分镜脚本生成**:
   - 将章节内容转换为分镜脚本
   - 每个分镜包含:
     - 分镜序号
     - 场景描述
     - 解说文案（narration）
     - 台词（dialogue，如果有）
     - 景别信息（close-up, medium, wide等）
4. **批量处理**: 对多个章节进行批量生成（支持并发）

#### 1.5 质量检查阶段
在生成过程中进行实时质量检查：

1. **完整性检查**:
   - 检查每个分镜是否都有解说文案
   - 检查章节是否完整生成
   - 检查是否有遗漏的分镜

2. **格式规范性检查**:
   - 检查XML格式是否正确
   - 检查必需字段是否都存在
   - 检查数据结构是否符合规范

3. **内容连贯性检查**:
   - 检查分镜之间的逻辑连贯性
   - 检查场景转换是否合理
   - 检查文案风格是否统一

4. **问题标记**:
   - 标记不符合要求的分镜
   - 记录检查结果和问题描述

#### 1.6 输出保存阶段
1. **XML文件生成**:
   - 将生成的解说文案保存为XML格式
   - 文件路径: `data/001/script/narration.xml`
   - XML结构包含:
     ```xml
     <script>
       <chapter id="1" title="第一章">
         <shot id="1" sequence="1">
           <scene>场景描述</scene>
           <narration>解说文案</narration>
           <dialogue>台词（可选）</dialogue>
           <shot_type>close-up</shot_type>
         </shot>
         ...
       </chapter>
       ...
     </script>
     ```

2. **日志和报告生成**:
   - 生成日志文件: `data/001/script/generation.log`
   - 生成检查报告: `data/001/script/check_report.json`
   - 报告包含:
     - 生成统计（章节数、分镜数等）
     - 检查结果汇总
     - 问题列表和位置

#### 1.7 错误处理
- **生成失败**: 
  - 记录错误信息到日志
  - 标记失败的章节
  - 支持重试机制
- **检查失败**: 
  - 记录问题到报告
  - 标记需要修复的分镜
  - 继续处理其他分镜

### 输出结果
- ✅ 解说文案XML文件（初稿）
- ✅ 生成日志文件
- ✅ 质量检查报告

---

## 步骤2: 验证解说文案字数（自动修复）

### 命令
```bash
python validate_narration.py data/001 --auto-fix
```

### 功能描述
验证生成的解说文案字数是否符合要求，并在启用 `--auto-fix` 时自动修复不符合要求的部分。

### 详细处理流程

#### 2.1 输入准备
- **输入路径**: `data/001` (工作流数据目录)
- **输入文件**: 步骤1生成的解说文案XML文件
- **参数选项**:
  - `--auto-fix`: 启用自动修复功能
  - `--min-words`: 最小字数要求（可选，默认值）
  - `--max-words`: 最大字数要求（可选，默认值）

#### 2.2 字数统计阶段
1. **XML文件解析**:
   - 读取步骤1生成的XML文件
   - 解析XML结构，提取所有分镜的解说文案

2. **字数统计**:
   - 对每个分镜的解说文案进行字数统计
   - 统计方式:
     - 中文字符: 每个字符计1字
     - 英文单词: 每个单词计1字
     - 标点符号: 不计入字数
     - 数字: 每个数字计1字
   - 记录统计结果:
     ```json
     {
       "chapter_1": {
         "shot_1": {
           "word_count": 45,
           "narration": "解说文案内容..."
         },
         ...
       }
     }
     ```

#### 2.3 字数验证阶段
1. **规则定义**:
   - 默认规则:
     - 最小字数: 20字（可配置）
     - 最大字数: 100字（可配置）
     - 推荐字数: 40-60字
   - 自定义规则: 可通过配置文件或参数指定

2. **验证检查**:
   - 遍历所有分镜，检查每个分镜的字数
   - 分类标记:
     - ✅ **符合要求**: 字数在合理范围内
     - ⚠️ **字数过少**: 字数 < 最小字数要求
     - ⚠️ **字数过多**: 字数 > 最大字数要求
     - ❌ **严重异常**: 字数 = 0 或字数 > 200

3. **问题汇总**:
   - 统计不符合要求的分镜数量
   - 按问题类型分类（过少/过多）
   - 记录问题分镜的位置和详情

#### 2.4 自动修复阶段（启用 `--auto-fix` 时）

##### 2.4.1 字数过多的修复
1. **问题识别**: 找出字数 > 最大字数要求的分镜
2. **AI改写**:
   - 调用AI服务（Gemini3 Pro、豆包等）
   - 构建改写Prompt:
     ```
     请将以下解说文案精简到{目标字数}字以内，保持核心信息和语义完整：
     {原始文案}
     ```
   - 获取改写后的文案
3. **质量检查**:
   - 检查改写后的字数是否符合要求
   - 检查语义是否保持完整
   - 检查风格是否一致
4. **替换更新**: 将改写后的文案替换原文案

##### 2.4.2 字数过少的修复
1. **问题识别**: 找出字数 < 最小字数要求的分镜
2. **AI补充**:
   - 调用AI服务
   - 构建补充Prompt:
     ```
     请将以下解说文案补充到至少{最小字数}字，保持语义完整和风格一致：
     {原始文案}
     上下文: {前后分镜的文案}
     ```
   - 获取补充后的文案
3. **质量检查**:
   - 检查补充后的字数是否符合要求
   - 检查补充内容是否合理
   - 检查是否与上下文连贯
4. **替换更新**: 将补充后的文案替换原文案

##### 2.4.3 修复后验证
1. **重新统计**: 对修复后的文案重新进行字数统计
2. **二次验证**: 再次检查字数是否符合要求
3. **修复记录**: 记录修复前后的对比
   ```json
   {
     "shot_id": "shot_1",
     "before": {
       "word_count": 120,
       "status": "too_long"
     },
     "after": {
       "word_count": 58,
       "status": "valid"
     },
     "fixed": true
   }
   ```

#### 2.5 验证报告生成
1. **报告内容**:
   - 总体统计:
     - 总分镜数
     - 符合要求的分镜数
     - 不符合要求的分镜数（修复前/修复后）
   - 详细列表:
     - 每个分镜的字数统计
     - 问题分镜的详情
     - 修复记录（如果启用自动修复）
   - 建议:
     - 需要人工检查的分镜
     - 可能需要重新生成的分镜

2. **报告格式**:
   - JSON格式: `data/001/script/validation_report.json`
   - 文本格式: `data/001/script/validation_report.txt`

#### 2.6 文件更新
1. **XML文件更新**:
   - 如果启用自动修复，更新原始XML文件
   - 备份原文件: `data/001/script/narration.xml.bak`
   - 保存修复后的文件: `data/001/script/narration.xml`

2. **元数据更新**:
   - 更新分镜的字数信息
   - 标记修复状态
   - 记录修复时间

#### 2.7 错误处理
- **验证失败**: 
  - 记录验证错误到日志
  - 标记无法验证的分镜
  - 继续处理其他分镜
- **修复失败**: 
  - 记录修复失败的分镜
  - 标记为需要人工处理
  - 保留原始文案

### 输出结果
- ✅ 验证报告（JSON + 文本格式）
- ✅ 修复后的解说文案XML文件（如果启用自动修复）
- ✅ 修复记录和对比数据

---

## 数据流转

```
原始文本文件 (TXT/Word/PDF/图片)
    ↓
[步骤1: gen_script_v2.py]
    ↓
解说文案XML文件（初稿）
    ├── narration.xml
    ├── generation.log
    └── check_report.json
    ↓
[步骤2: validate_narration.py --auto-fix]
    ↓
解说文案XML文件（最终版）
    ├── narration.xml (修复后)
    ├── narration.xml.bak (备份)
    ├── validation_report.json
    └── validation_report.txt
    ↓
保存到工作流数据
    └── data/001/script/
```

## 质量保证机制

### 步骤1的质量检查
- ✅ 完整性检查：确保所有分镜都有文案
- ✅ 格式检查：确保XML格式正确
- ✅ 连贯性检查：确保内容逻辑连贯

### 步骤2的质量检查
- ✅ 字数合理性检查：确保字数在合理范围内
- ✅ 语义一致性检查：修复后保持语义完整
- ✅ 风格统一性检查：确保风格一致

### 自动修复机制
- ✅ 字数过多：自动精简，保持核心信息
- ✅ 字数过少：自动补充，保持语义完整
- ✅ 修复验证：修复后重新验证，确保符合要求

## 注意事项

1. **步骤顺序**: 必须先执行步骤1，再执行步骤2
2. **文件依赖**: 步骤2依赖步骤1生成的XML文件
3. **自动修复**: 建议启用 `--auto-fix` 以确保文案质量
4. **人工审核**: 修复后的文案建议进行人工审核
5. **备份机制**: 自动修复会备份原文件，可随时恢复

## API接口对应

### 步骤1对应接口
- `POST /api/v1/workflow/script` - 创建剧本生成任务
- `GET /api/v1/workflow/script/:id` - 查询生成结果

### 步骤2对应接口
- `POST /api/v1/workflow/script/validate` - 验证剧本字数
- `GET /api/v1/workflow/script/validate/:id` - 查询验证结果
